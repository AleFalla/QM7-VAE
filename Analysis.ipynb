{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b76ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 16:09:21.493516: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-08 16:09:21.493745: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from schnetpack import AtomsData, AtomsLoader\n",
    "from ase.visualize import view\n",
    "import torch \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "from qml.representations import *\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from VAE import base_VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c0a52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa82c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaebacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json('./dataframe41537.json') #or whatever dataset you want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870151c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for prop_ls_NN:\n\tMissing key(s) in state_dict: \"model.0.weight\", \"model.0.bias\", \"model.2.weight\", \"model.2.bias\", \"model.4.weight\", \"model.4.bias\". \n\tUnexpected key(s) in state_dict: \"model_mu.0.weight\", \"model_mu.0.bias\", \"model_mu.2.weight\", \"model_mu.2.bias\", \"model_mu.4.weight\", \"model_mu.4.bias\", \"model_logvar.0.weight\", \"model_logvar.0.bias\", \"model_logvar.2.weight\", \"model_logvar.2.bias\", \"model_logvar.4.weight\", \"model_logvar.4.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31402/3679507968.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#torch.save(last_model.state_dict(), PATH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop_ls_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for prop_ls_NN:\n\tMissing key(s) in state_dict: \"model.0.weight\", \"model.0.bias\", \"model.2.weight\", \"model.2.bias\", \"model.4.weight\", \"model.4.bias\". \n\tUnexpected key(s) in state_dict: \"model_mu.0.weight\", \"model_mu.0.bias\", \"model_mu.2.weight\", \"model_mu.2.bias\", \"model_mu.4.weight\", \"model_mu.4.bias\", \"model_logvar.0.weight\", \"model_logvar.0.bias\", \"model_logvar.2.weight\", \"model_logvar.2.bias\", \"model_logvar.4.weight\", \"model_logvar.4.bias\". "
     ]
    }
   ],
   "source": [
    "from separate_models import prop_ls_NN, prop_mol_NN\n",
    "\n",
    "#load the direct model you prefer:\n",
    "#'./main_testing/direct_global_1/trained_N' with N=0-14 for the global tested configurations\n",
    "#'./main_testing/direct_local_{}/trained' with N=0-4 for the local in the order \"hDIP\", \"vdWR\", \"atPOL\",\"hCHG\"\n",
    "prop_list=list(df.columns[df.columns != 'BoB'])[8:53] #decide which properties you want\n",
    "latent_size=32\n",
    "input_dim=528\n",
    "\n",
    "#load direct\n",
    "PATH='./main_testing/direct_global_1/trained_0'\n",
    "model_direct = prop_mol_NN(mol_size=input_dim,prop_size=len(prop_list),extra_size=32-len(prop_list))\n",
    "\n",
    "#load the regular joint model (made of vae and mlp) you prefer:\n",
    "#VAE part:\n",
    "#'./main_testing/joint_global_1/vae_trained/trained_N' with N=0-14 for the global tested configurations\n",
    "#'./main_testing/joint_local_N/vae_trained/trained' with N=0-4 for the local in the order \"hDIP\", \"vdWR\", \"atPOL\",\"hCHG\"\n",
    "#MLP part\n",
    "#'./main_testing/joint_global_1/joint_trained/trained_N' with N=0-14 for the global tested configurations\n",
    "#'./main_testing/joint_local_N/joint_trained/trained' with N=0-4 for the local in the order \"hDIP\", \"vdWR\", \"atPOL\",\"hCHG\"\n",
    "\n",
    "#load vae regular \n",
    "PATH='./main_testing/joint_global_1/vae_trained/trained_0'\n",
    "model_vae = base_VAE(input_dim=input_dim, latent_size=latent_size)\n",
    "model_vae.load_state_dict(torch.load(PATH))\n",
    "#load mlp for regular vae\n",
    "PATH='./main_testing/joint_global_1/joint_trained/trained_0' \n",
    "model_mlp_vae = prop_ls_NN(latent_size=latent_size,prop_size=len(prop_list))\n",
    "model_mlp_vae.load_state_dict(torch.load(PATH))\n",
    "\n",
    "#load the 'improved' joint model (made of vae and mlp) you prefer:\n",
    "#VAE part:\n",
    "#'./main_testing/joint_extra_global_1/vae_trained/trained_N' with N=0-14 for the global tested configurations\n",
    "#'./main_testing/joint_local_extra_{}/vae_trained/trained' with N=0-4 for the local in the order \"hDIP\", \"vdWR\", \"atPOL\",\"hCHG\"\n",
    "#MLP part\n",
    "#'./main_testing/joint_extra_global_1/joint_trained/trained_N' with N=0-14 for the global tested configurations\n",
    "#'./main_testing/joint_local_extra_{}/joint_trained/trained' with N=0-4 for the local in the order \"hDIP\", \"vdWR\", \"atPOL\",\"hCHG\"\n",
    "\n",
    "#load vae+ \n",
    "PATH='./main_testing/joint_extra_global_1/vae_trained/trained_0'\n",
    "model_vaep = base_VAE(input_dim=input_dim, latent_size=latent_size)\n",
    "model_vaep.load_state_dict(torch.load(PATH))\n",
    "#load mlp for vae+\n",
    "PATH='./main_testing/joint_global_1/joint_trained/trained_0' \n",
    "model_mlp_vaep = prop_ls_NN(latent_size=latent_size,prop_size=len(prop_list))\n",
    "model_mlp_vaep.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80571184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here define a bunch of functions for dataset operations\n",
    "\n",
    "def perc_error(a,b):\n",
    "    a=torch.Tensor(a).abs()\n",
    "    b=torch.Tensor(b)\n",
    "    numer=torch.sum((a-b).abs())\n",
    "    denom=torch.sum(b.abs())\n",
    "    return 100*torch.mean(numer/denom)\n",
    "\n",
    "def to_latent_mlp(x,model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x=torch.reshape(x,(1,x.size()[0]))\n",
    "        u_reco,logvar=model(x)\n",
    "    return u_reco\n",
    "\n",
    "def to_latent_vae(x,model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x=torch.reshape(x,(1,x.size()[0]))\n",
    "        u_reco,logvar=model.encode(x)\n",
    "    return u_reco\n",
    "\n",
    "def to_reco_vae (u, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        u=torch.reshape(u,(1,u.size()[0]))\n",
    "        x_reco,logvar=model.decode(u)\n",
    "    return x_reco\n",
    "\n",
    "def to_reco_direct (x, model):\n",
    "    model.eval()\n",
    "        with torch.no_grad():\n",
    "            x=torch.reshape(x,(1,x.size()[0]))\n",
    "            x_reco,logvar=model(x)\n",
    "        return x_reco\n",
    "\n",
    "\n",
    "#full analysis, returns dataset with different latent representations and various errors (if it works since I never tested it)\n",
    "\n",
    "def analysis(df, direct_model, vae_regular, mlp_regular, vae_plus, mlp_plus, prop_list):\n",
    "    \n",
    "    #for the direct model\n",
    "    df['reconstructed_direct']=df[prop_list].apply(lambda x: to_reco_direct(torch.Tensor(x),direct_model)[0].tolist(),axis=1)\n",
    "    df['error_reco_direct']=df[['reconstructed_direct','BoB']].apply(lambda x: perc_error(*x),axis=1)\n",
    "    df['error_reco_direct']=df['error_reco_direct'].apply(lambda x: x.item())\n",
    "\n",
    "    #for the standard vae joint implementation (both latent from vae and mlp and errors in reconstruction from vae and from mlp+vae)\n",
    "    df['latent_vae_regular']=df[prop_list].apply(lambda x: to_latent_vae(torch.Tensor(x),vae_regular)[0].tolist(),axis=1)\n",
    "    df['reconstructed_vae_regular']=df['latent_vae_regular'].apply(lambda x: to_reco(torch.Tensor(x),vae_regular).tolist())\n",
    "    df['error_reco_vae_regular']=df[['reconstructed_vae_regular','BoB']].apply(lambda x: perc_error(*x),axis=1)\n",
    "    df['error_reco_vae_regular']=df['error_reco_vae_regular'].apply(lambda x: x.item())\n",
    "\n",
    "    df['latent_mlp_regular']=df[prop_list].apply(lambda x: to_latent_vae(torch.Tensor(x),mlp_regular)[0].tolist(),axis=1)\n",
    "    df['reconstructed_joint_regular']=df['latent_mlp_regular'].apply(lambda x: to_reco(torch.Tensor(x),vae_regular).tolist())\n",
    "    df['error_reco_joint_regular']=df[['reconstructed_joint_regular','BoB']].apply(lambda x: perc_error(*x),axis=1)\n",
    "    df['error_reco_joint_regular']=df['error_reco_joint_regular'].apply(lambda x: x.item())\n",
    "\n",
    "\n",
    "    #for the 'improved' vae joint implementation (both latent from vae and mlp and errors in reconstruction from vae and from mlp+vae)\n",
    "    df['latent_vae_plus']=df[prop_list].apply(lambda x: to_latent_vae(torch.Tensor(x),vae_plus)[0].tolist(),axis=1)\n",
    "    df['reconstructed_vae_plus']=df['latent_vae_plus'].apply(lambda x: to_reco(torch.Tensor(x),vae_plus).tolist())\n",
    "    df['error_reco_vae_plus']=df[['reconstructed_vae_plus','BoB']].apply(lambda x: perc_error(*x),axis=1)\n",
    "    df['error_reco_vae_plus']=df['error_reco_vae_plus'].apply(lambda x: x.item())\n",
    "\n",
    "    df['latent_mlp_plus']=df[prop_list].apply(lambda x: to_latent_vae(torch.Tensor(x),mlp_plus)[0].tolist(),axis=1)\n",
    "    df['reconstructed_joint_plus']=df['latent_mlp_plus'].apply(lambda x: to_reco(torch.Tensor(x),vae_plus).tolist())\n",
    "    df['error_reco_joint_plus']=df[['reconstructed_joint_plus','BoB']].apply(lambda x: perc_error(*x),axis=1)\n",
    "    df['error_reco_joint_plus']=df['error_reco_joint_plus'].apply(lambda x: x.item())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e62ef7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.35655108698269"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyzed=analysis(df=df,direct_model=model_direct, vae_regular=model_vae, mlp_regular=model_mlp_vae, vae_plus=model_vaep, mlp_plus=model_mlp_vap, prop_list=prop_list)\n",
    "df_analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbbd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here you can do all the analysis you want, PCA in latent space, histograms, plots or whatever. When I have time I will set this stuff up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
